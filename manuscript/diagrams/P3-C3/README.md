# P3-C3 Reinforcement Learning Basics - Diagrams

This directory contains Mermaid diagrams for Chapter P3-C3: Reinforcement Learning Basics.

## Diagram List

1. **figure-1-rl-loop.mmd** - Basic RL loop showing agent-environment interaction, state/action/reward flow, and policy updates.

2. **figure-2-reward-design.mmd** - Comparison of poor vs good reward design for a navigation task, showing how reward components shape behavior.

3. **figure-3-value-policy.mmd** - Conceptual diagram illustrating value functions and policies as two complementary ways of thinking about RL behavior, with connections to Q-learning, policy gradients, and actor-critic methods.

4. **figure-4-exploration-exploitation.mmd** - Exploration-exploitation trade-off over training, showing how emphasis shifts from exploration (early) to exploitation (later), and the balance needed for efficient learning.

## Style Notes

- Diagrams use consistent color palette from global style guide
- Conceptual focus (no detailed equations or algorithms)
- Emphasis on intuition and robotics-relevant examples
- Black & white readable (colors are supplementary)

## Usage

These diagrams support the conceptual introduction to RL in Part 3, setting up more advanced RL topics in Part 4.

