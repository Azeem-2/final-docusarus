graph TD
    A[Robotics Applications] --> B[Visual Question Answering<br/>VQA]
    A --> C[Object Grounding<br/>Language → Location]
    A --> D[Language-to-Action<br/>Commands → Actions]
    A --> E[Scene Understanding<br/>Multi-Image Reasoning]
    
    B --> F[Image + Question<br/>→ Answer]
    C --> G[Language Description<br/>→ Visual Location]
    D --> H[Natural Language<br/>→ Robot Actions]
    E --> I[Multiple Views<br/>→ Spatial Understanding]
    
    J[Use Cases] --> K[Human-Robot Interaction<br/>Natural Communication]
    J --> L[Manipulation<br/>Language-Guided Grasping]
    J --> M[Navigation<br/>Language-Guided Movement]
    
    style A fill:#4A90E2,stroke:#2E5C8A,color:#fff
    style B fill:#E8F4F8,stroke:#4A90E2
    style C fill:#F0F8E8,stroke:#7CB342
    style D fill:#FFF3E0,stroke:#FF9800
    style E fill:#F3E5F5,stroke:#9C27B0

